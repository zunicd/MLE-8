{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo4cOpESDE8L"
      },
      "source": [
        "<p align = \"center\" draggable=‚Äùfalse‚Äù ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
        "     width=\"200px\"\n",
        "     height=\"auto\"/>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObWXrU23GK0q"
      },
      "source": [
        "# **Bonus Challenge! - Taking it to the Next Level üì∂**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjujsFMuGgDi"
      },
      "source": [
        "## :coffee: Starbucks Promotional Offers\n",
        "\n",
        "Starbucks Corporation is the leading roaster, retailer, and marketer of specialty coffee in the world.  Starbucks' mobile app routinely pushes offers to customers in hopes that it will entice the customer to visit to one of their many local coffeehouses.   The offers may be promotional like a **discount** on a seasonal beverage or pastry or **BOGO (Buy One Get One free)** or an **informational** whichs is an advertisement for a product.  Some users may receive offers more frequently than others.  \n",
        "\n",
        "In this challenge:\n",
        "\n",
        "1. We want to predict the responsiveness of a customer to an offer - i.e. how likely they are to make a purchase after receiving an offer.\n",
        "\n",
        "2. We will use Spark and will introduce the Pandas on Spark API - this will help out with your Exploratory Data Analysis (EDA) and Feature Engineering.\n",
        "\n",
        "3. You will be responsible for the majority of coding in the section, but you will be not left alone!  If you get stuck, look at the dropdown hints (ü§î **Hints**).  The hints will start off vague and get increasingly more specific to help guide you through the challenge.\n",
        "\n",
        "5. You will use **multiclass classification** techniques in Spark to classify customer responsiveness to promotional offer campaigns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paKwFVLVRdY9"
      },
      "source": [
        "# Multiclass (Multi-label) Classification\n",
        "\n",
        "[Multiclass classification](https://en.wikipedia.org/wiki/Multi-label_classification) is an extension of binary classification with more than two labels where each label is an binary classification model.  The model that produces the highest probability score for the label is the label becomes the label prediction for the input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Spark Environment\n",
        "### Make sure to run this notebook in your Spark environment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmxcQnv4FWxi"
      },
      "source": [
        "# **Get the Data**\n",
        "\n",
        "There are three datasets in this challenge.  **Portfolio** contains the different offer campaigns, **Profile** contains the customer profile, and **Transcript** contains the user interactions with the offer campaigns.  Have a look üëÄ for yourself!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Love üêº Pandas?  Love Spark? Let's combine them!  Born out of a Databricks project called üê® Koalas, [Pandas on Spark](https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/index.html), allows us to utilize the Pandas API distributed on Spark!  Check out this [article](https://towardsdatascience.com/run-pandas-as-fast-as-spark-f5eefe780c45) for a nice quickstart as well as the official [API Documentation](https://spark.apache.org/docs/3.3.0/api/python/reference/index.html)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQkW13CM_HI8"
      },
      "outputs": [],
      "source": [
        "import pyspark.pandas as ps\n",
        "\n",
        "psdf_portfolio = ps.read_csv(\"../dat/portfolio.csv\")\n",
        "psdf_profile = ps.read_csv(\"../dat/profile.csv\")\n",
        "psdf_transcript = ps.read_csv(\"../dat/transcript.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IKEXkdgwLn5A",
        "outputId": "2021f231-7ffd-4d5e-eab1-898a01a2ddca"
      },
      "outputs": [],
      "source": [
        "psdf_portfolio.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6chY2ZPYLnxb",
        "outputId": "65851ad2-1f2f-4189-b810-d554451a7471"
      },
      "outputs": [],
      "source": [
        "psdf_profile.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_e5sSudULp6m",
        "outputId": "53aad82d-e276-4529-c0b1-df0e9e79d49e"
      },
      "outputs": [],
      "source": [
        "psdf_transcript.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWkx_mp-Fr0d"
      },
      "source": [
        "# **Explore the Data - EDA**\n",
        "\n",
        "It's your turn to practice EDA!  Perform either manual EDA or use automated EDA tools like SweetViz!  Get to know the data, what do you notice, what stands out?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ivJArUnGAgL"
      },
      "source": [
        "## **ü§î Hints**\n",
        "<details>\n",
        "<summary>Hint 1</summary>\n",
        "Take a look at each dataset independently.  What do you notice?  Are there any missing values? Are there values that don't make sense? What are the unique events?\n",
        "<br></br>\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 2</summary>\n",
        "Is the dataset balanced?  \n",
        "<br></br>\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 3</summary>\n",
        "Notice that the challenge is to predict customer responsiveness. How can responsiveness be represented in the data?\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eH_4dskOi06"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE GOES HERE!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-ItAwuBOKPx"
      },
      "source": [
        "# **Setup the ETL Pipeline + Feature Engineering (The Art üé® üñå of ML**)\n",
        "\n",
        "Bring the datasets together, perform feature engineering, rename columns, and drop columns that you don't need for predictions.\n",
        "\n",
        "**Required**: Create a feature for customer responsiveness using the event column in the transcript table.  \n",
        "\n",
        "  *   Create **five** labels (one for each event + unresponsive) for customer responsiveness using a 5-point Likert scale:\n",
        "  \n",
        "    1. Unresponsive, \n",
        "    2. Slightly Responsive, \n",
        "    3. Somewhat Responsive \n",
        "    4. Moderately Responsive,\n",
        "    5. Very Responsive.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaiLidnAPZX5"
      },
      "source": [
        "## **ü§î Hints**\n",
        "<details>\n",
        "<summary>Hint 1</summary>\n",
        "Take a look at the AGE, GENDER, and INCOME variables.  Do you notice anything unusual?  Do the values make sense?  How will you handle this?\n",
        "<br></br>\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 2</summary>\n",
        "Are there any other features that you could create features for?  \n",
        "<br></br>\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 3</summary>\n",
        "As you bring the datasets together, what do you notice about the relationship between the customer and transcript tables?  Is it a one-to-one or a one-to-many relationship?\n",
        "<br></br>\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 4</summary>\n",
        "Since the data has a one-to-many relationship between the customer and transcript tables. You will need flatten your dataset (i.e. in one row per customer).\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 5</summary>\n",
        "Create binary features (dummy variables) for the channels, offer_type, and event variables.  Use the event dummy variables to create your customer responsiveness labels.\n",
        "<br></br>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Here's a freebie! Let's create a row-level function to parse out the offer id value. This probably won't be the last time that you'll need it! üòâ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Row-level function to clean offer id in transcript table.\n",
        "def get_offer_id(offer_id):\n",
        "  offer_id = offer_id.split()[2]\n",
        "  return offer_id[1:len(offer_id)-2]\n",
        "\n",
        "psdf_transcript[\"offer_id\"] = psdf_transcript[\"value\"].apply(get_offer_id)\n",
        "\n",
        "# Drop original value column\n",
        "psdf_transcript = psdf_transcript.drop(\"value\")\n",
        "\n",
        "psdf_transcript.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsrTMOHa_0ZY"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE GOES HERE!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYawts9PO-AH"
      },
      "source": [
        "# **Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t4ZLm1YpnE8"
      },
      "source": [
        "## Prepare your dataset for ML!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wW0ko0ZXprLA"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "\n",
        "# YOUR CODE GOES HERE!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM5vPGxft2Ya"
      },
      "source": [
        "## Train-Test-Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIXDfBZWt1OR"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE GOES HERE!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9STUxFRbv6z"
      },
      "source": [
        "There are a couple different ways to setup a multiclass classifier as an extension of Logistic Regression in PySpark: \n",
        "\n",
        "1.   Multinomial Logistic Regression (softmax)\n",
        "2.   One vs Rest (OVR) / One vs All (OVA)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shEhjODgkrh1"
      },
      "source": [
        "### Multinomial Logistic Regression (softmax)\n",
        "\n",
        "Logistic Regression can be adapted to a multiclass task by using the setting the `family = \"multinomial\"`.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UpwvX4AYZQj"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Instantiate the classifier\n",
        "\n",
        "# Fit the model \n",
        "# YOUR CODE GOES HERE!\n",
        "\n",
        "# Make Predictions\n",
        "# YOUR CODE GOES HERE!\n",
        "\n",
        "# Evaluate the model\n",
        "# YOUR CODE GOES HERE!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVbKFX4HPOPQ"
      },
      "source": [
        "### One vs Rest (OVR) / One vs All (OVA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NJnvQdHPXAS"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# instantiate the base Logistic Regression classifier.\n",
        "\n",
        "# instantiate the One Vs Rest Classifier.\n",
        "ovr = OneVsRest(classifier=lr)\n",
        "\n",
        "# Fit the model \n",
        "# YOUR CODE GOES HERE!\n",
        "\n",
        "# Make Predictions\n",
        "# YOUR CODE GOES HERE!\n",
        "\n",
        "# Evaluate the model\n",
        "# YOUR CODE GOES HERE!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koxKO3MulNV2"
      },
      "source": [
        "## Setup Your Modeling Pipeline with Hyper Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2t0AxGwlUuS"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# YOUR CODE GOES HERE!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzwHyWG61gBo"
      },
      "source": [
        "Additionally, you can solve Multiclass Classification problems using:\n",
        "\n",
        "1.   Random Forest\n",
        "2.   Decision Trees\n",
        "3.   Na√Øve Bayes\n",
        "\n",
        "You can also extend the idea of multiclass classification to [multi-label multiclassification](https://en.wikipedia.org/wiki/Multi-label_classification).\n",
        "\n",
        "But that's another lesson..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Review Questions\n",
        "\n",
        "1.  What are two other applications you could use multiclass classification for?\n",
        "2.  What do you think the drawbacks to multiclass classifications are?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Starbucks Multiclass Classification",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.0b3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
