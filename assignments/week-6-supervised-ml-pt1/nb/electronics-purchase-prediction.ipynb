{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=”false” ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9MqC-OwPKyQ"
   },
   "source": [
    "# <h1 align=\"center\" id=\"heading\">Eletronics Purchase Prediction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9MqC-OwPKyQ"
   },
   "source": [
    "Today you are a machine learning engineer in the Department of Marketing and Inventory at Walmart Labs. You have access to the Walmart server data, specifically the Electronics section. However, there is no customer facing information, but you do have access to timestamped data regarding product viewing/carting/purchasing. We will use this data to build a model of whether or not some product will be purchased.\n",
    "\n",
    "Data is adapted from [e-commerce behavior data on Kaggle](https://www.kaggle.com/mkechinov/ecommerce-behavior-data-from-multi-category-store). \n",
    "\n",
    "This file contains behavior data from a large multi-category store. Each row in the file rerepresents an event. All events are related to products and users. Each event is like many-many relation between users and products. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this session, you will be able to\n",
    "- Detect data imbalance\n",
    "- Practice more on preprocessing features\n",
    "- Build logistic regression / SVM / Gradient Boosting / Random Forest models\n",
    "- Evaluate models with proper metrics\n",
    "- Interpret black box models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dR-vbsrRTv_"
   },
   "source": [
    "## Task 1: Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dR-vbsrRTv_"
   },
   "source": [
    "We start by looking at the descriptions before loading in the csv files.\n",
    "\n",
    "1. Use the `IPython.display` module to view the `some_column_descriptions.png` file. Look through the column names and descriptions to get an idea of what the data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "executionInfo": {
     "elapsed": 1253,
     "status": "ok",
     "timestamp": 1628175773190,
     "user": {
      "displayName": "Spencer Kent",
      "photoUrl": "",
      "userId": "07841346171340846448"
     },
     "user_tz": 360
    },
    "id": "h9EE7PccRRc9",
    "outputId": "d0c4ead6-d26a-465a-ea5f-140913936192"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "# change the filename to wherever you downloaded/uploaded the file\n",
    "filename = '../img/some_column_descriptions.png'\n",
    "display(Image(filename=filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzZiHeyvPKyW"
   },
   "source": [
    "The dataset has User-journey data, i.e., it tracks information user/product pairs over time to see if the combination results in a purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzZiHeyvPKyW"
   },
   "source": [
    "2. Look at the `user_journey_descriptions.png` file. Review the data sample to get a sense of what information we are tracking for each user/product pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 712,
     "status": "ok",
     "timestamp": 1628175803603,
     "user": {
      "displayName": "Spencer Kent",
      "photoUrl": "",
      "userId": "07841346171340846448"
     },
     "user_tz": 360
    },
    "id": "MU87_Tt-TLff",
    "outputId": "629943bc-95f5-4d92-a88a-697dc7b75535"
   },
   "outputs": [],
   "source": [
    "# change path to wherever you uploaded/downloaded the file\n",
    "filename='../img/user_journey_descriptions.png'\n",
    "display(Image(filename=filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSNM0etdU6HR"
   },
   "source": [
    "The dataset we are working with is essentially what we have screenshotted above, but has been anonymized by removing product IDs and user IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSNM0etdU6HR"
   },
   "source": [
    "3. Use the pandas `read_csv()` and `head()` functions to read in the training data (`../dat/train.csv.gz`) and look at the first few rows.\n",
    "\n",
    "    Note the `Purchase` column has either 0 (not purchased) or 1 (purchased)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is the dimension of the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE # (645816, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Similarly, read in the test data `../dat/test.csv.gz` and check its dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df # YOUR CODE HERE\n",
    "test_df.shape # (430544, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JunsLTrHPKyZ"
   },
   "source": [
    "## Task 2: Understand data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JunsLTrHPKyZ"
   },
   "source": [
    "Our goal here is to predict whether a customer/product pair will result in a purchase. As part of this, we will want to identify what features are most important for making this classification.\n",
    "\n",
    "We'll start with digging into our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xee_TNNyYHSy"
   },
   "source": [
    "1. For the training data, print out the datatype of each feature (column), and identify which ones are non-numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2QfKLnzYXqA"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details> \n",
    "<summary>Expected output:</summary>\n",
    "\n",
    "    NumOfEventsInJourney      int64\n",
    "    NumSessions               int64\n",
    "    interactionTime         float64\n",
    "    maxPrice                float64\n",
    "    minPrice                float64\n",
    "    NumCart                   int64\n",
    "    NumView                   int64\n",
    "    InsessionCart             int64\n",
    "    InsessionView             int64\n",
    "    year                      int64\n",
    "    month                     int64\n",
    "    weekday                  object\n",
    "    timeOfDay                object\n",
    "    Weekend                   int64\n",
    "    Purchase                  int64\n",
    "    dtype: object\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Print the unique values for the year, month and weekend features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('   year:', # YOUR CODE HERE # [2019]\n",
    "print('  month:', # YOUR CODE HERE # [11]\n",
    "print('weekend:', # YOUR CODE HERE # [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does weekend: 0 mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Since these columns each only have one unique value, they will not be valuable features, we drop the three columns in the training set. Pass the `columns` argument to the `.drop()` method. Make sure to use `inplace=True` to modify the DataFrame. Print the shape of the DataFrames to verify the columns were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape) \n",
    "# YOUR CODE HERE\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details> \n",
    "<summary>Expected output:</summary>\n",
    "\n",
    "   (645816, 15)\n",
    "   \n",
    "   (645816, 12)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Repeat the step for `test_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.shape)\n",
    "# YOUR CODE HERE\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details> \n",
    "<summary>Expected output:</summary>\n",
    "\n",
    "(430544, 15)\n",
    "\n",
    "(430544, 12)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhnGXhKlY00_"
   },
   "source": [
    "4. For each non-numeric feature, print the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIz5JdgYY6-x"
   },
   "outputs": [],
   "source": [
    "print('  weekday:', # YOUR CODE HERE\n",
    "print('timeOfDay:', # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Expected output:</summary>\n",
    "  \n",
    "  weekday: ['Wed' 'Fr' 'Sat' 'Sun' 'Tue' 'Thu' 'Mon']\n",
    "\n",
    "timeOfDay: ['EarlyMorning' 'Morning' 'Afternoon' 'Dawn' 'Evening' 'Night' 'Noon']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LzuyL8gZXNy"
   },
   "source": [
    "5. Convert the non-numeric features to numeric. \n",
    "\n",
    "    These feature values are ordered temporally, so it makes sense to do so. Follow the example given for the `weekday` column to update the `timeOfDay` column. Use the `.head()` method to inspect the dataset after the transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HN503xCOPKyf"
   },
   "outputs": [],
   "source": [
    "weekday_str2num = {\n",
    "    s: i+1 for i, s in enumerate(['Mon', 'Tue', 'Wed', 'Thu', 'Fr', 'Sat', 'Sun'])\n",
    "}\n",
    "train_df['weekday'] = train_df['weekday'].replace(weekday_str2num)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1eye5KePKym"
   },
   "outputs": [],
   "source": [
    "timeOfDay_str2num = # YOUR CODE HERE\n",
    "train_df['timeOfDay'] = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.timeOfDay.unique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary> Expected output:</summary>\n",
    "\n",
    "array([3, 1, 5, 4, 6, 2, 7])\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Do the same for `test_df`, that is, to convert `weekday` and `timeOfDay` into numeric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['weekday'] = # YOUR CODE HERE\n",
    "test_df['timeOfDay'] = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use the `Purchase` column in training set to determine the proportion of user journeys that result in purchases.  Are the datasets balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mab-Q3lKPKyo"
   },
   "outputs": [],
   "source": [
    "print(\"number of purchases vs non-purchases in train set:\")\n",
    "print(train_df.Purchase.value_counts())\n",
    "print(f\"percent of rows resulting in purchase: {}\") # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary> Expected output:</summary>\n",
    "\n",
    "    number of purchases vs non-purchases in train set:\n",
    "    0    636839\n",
    "    1      8977\n",
    "    Name: Purchase, dtype: int64\n",
    "    percent of rows resulting in purchase: 1.39%\n",
    "<details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHkECAjyPKyq"
   },
   "source": [
    "## Task 3: Remove highly correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlated features in general don't improve models (although it depends on the specifics of the problem like the number of variables and the degree of correlation), but they affect specific models in different ways and to varying extents:\n",
    "\n",
    "- For linear models (e.g., linear regression or logistic regression), [multicolinearity](https://en.wikipedia.org/wiki/Multicollinearity) can yield [solutions that are wildly varying and possibly numerically unstable](https://en.wikipedia.org/wiki/Multicollinearity#Consequences).\n",
    "- Random forests can be good at detecting interactions between different features, but highly correlated features can mask these interactions.\n",
    "More generally, this can be viewed as a special case of [Occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor). A simpler model is preferable, and, in some sense, a model with fewer features is simpler. The concept of [minimum description length](https://en.wikipedia.org/wiki/Minimum_description_length) makes this more precise ([ref](https://datascience.stackexchange.com/questions/24452/in-supervised-learning-why-is-it-bad-to-have-correlated-features))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHkECAjyPKyq"
   },
   "source": [
    "1. How many features does our dataset currently have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_4jlj1DPKyq"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>\n",
    "    \n",
    "    The training data currently has 11 features\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Draw a heatmap of the Pearson correlation.\n",
    "\n",
    "    The plotting code is given to you, but you need to fill in the calculation of the Pearson correlation (`pd.DataFrame.corr()`). Note that we here use a smaller sample of the total training dataset for calculating correlation and rendering heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small_df = train_df.copy().sample(n=int(1e4), random_state=12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "cor = # YOUR CODE HERE\n",
    "sns.heatmap(cor, vmin=-1, vmax=1, cmap=\"PiYG\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTbg-6-QPKyt",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Expected output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mV2VP1qRcU1O"
   },
   "source": [
    "3. Drop the features with high correlation.\n",
    "\n",
    "    We'll do this by looking at each pair of features, and if they are highly correlated (at least 0.8), we won't include the second feature in the pair. Store the remaining set of features (the ones you didn't drop) in dataframes `train_df_reduced`. You are given the code, make sure that you understand what each line does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kAcOhfzPKyx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "keep_columns = np.full(cor.shape[0], True)\n",
    "for i in range(cor.shape[0] - 1):\n",
    "    for j in range(i + 1, cor.shape[0] - 1):\n",
    "        if (np.abs(cor.iloc[i, j]) >= 0.8):\n",
    "            keep_columns[j] = False\n",
    "selected_columns = train_df.columns[keep_columns]\n",
    "train_df_reduced = train_df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(selected_columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. How many columns are left in the DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE # Expected: The training data now has 8 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_reduced.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Remove the same features from the test set and save in a new dataframe `test_df_reduced`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_reduced = # YOUR CODE HERE\n",
    "test_df_reduced.shape # Expected: (430544, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytOeqOQOd8Fu"
   },
   "source": [
    "6. Visualize the selected features and discuss your observations with your team.\n",
    "\n",
    "    Again, for faster rendering, use the subset `train_small_df_reduced`. If time permits, experiment with some other visualizations of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zr7RYNyPKy5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_small_df_reduced = train_small_df[selected_columns]\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "j = 0\n",
    "for i in train_df_reduced.columns:\n",
    "    plt.subplot(3, 4, j + 1)\n",
    "    j += 1\n",
    "    sns.histplot(train_small_df_reduced[i][train_small_df_reduced['Purchase'] == 0], color='g', label='no')\n",
    "    sns.histplot(train_small_df_reduced[i][train_small_df_reduced['Purchase'] == 1], color='r', label='yes')\n",
    "    plt.legend(loc='best')\n",
    "fig.suptitle('Subscription Feature Analysis')\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Make the NumPy arrays `X_train_reduced`, `X_test_reduced`, `y_train` and `y_test` from `train_df_reduced` and `test_df_reduced`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df_reduced['Purchase'].values\n",
    "y_test = # YOUR CODE HERE\n",
    "X_train_reduced = train_df_reduced.drop(columns='Purchase').values\n",
    "X_test_reduced = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Scale the features in `X_train_reduced` and `X_test_reduced` use `MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler =  # YOUR CODE HERE\n",
    "X_train_reduced = # YOUR CODE HERE\n",
    "X_test_reduced = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqG60zCOPKzF"
   },
   "source": [
    "## Task 4: Build logistic regression and SVM models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqG60zCOPKzF"
   },
   "source": [
    "We will be fitting both a Logistic Regression and SVM model to the reduced features and then looking at classification metrics such as Accuracy, Precision, Recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecEMOdxyPKzG"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score as accuracy,\n",
    "    recall_score as recall,\n",
    "    precision_score as precision,\n",
    "    f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qTOqA8oz107"
   },
   "source": [
    "1. Instantiate, train, and predict with the Logistic Regression model.\n",
    "\n",
    "    Make sure to account for the imbalanced classes with with `class_weight` parameter.\n",
    "\n",
    "    Remember to use the ***train*** data for building the model and the ***test*** data when making and evaluating the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sh5SBHJrPKzI"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_model = # YOUR CODE HERE\n",
    "lr_pred =  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5iHJRIC0Nfl"
   },
   "source": [
    "2. Calculate these classification metrics for the Logistic Regression model:\n",
    "\n",
    "    * accuracy\n",
    "    * precision\n",
    "    * recall\n",
    "    * f1 score\n",
    "    * confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHshtF_IPKzP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"accuracy:\", accuracy(y_test, lr_pred))\n",
    "print(\"precision:\", precision(y_test, lr_pred))\n",
    "print(\"recall:\", recall(y_test, lr_pred))\n",
    "print(\"f1 score:\", f1_score(y_test, lr_pred))\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pv858jlV1d__"
   },
   "source": [
    "4. Instantiate, train and predict with the SVM mode. Check [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) for usage. \n",
    "\n",
    "    Again, remember to account fo the imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1BXMFM2PKzR"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "svm_model = # YOUR CODE HERE \n",
    "svm_model.fit(X_train_reduced, y_train)\n",
    "svm_pred = svm_model.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ❓ What is the time complexity of SVM? What is it for Logistic Regression? Not familiar with the term \"time complexity\"? Take a read on [Computational Complexity of ML Models\n",
    "](https://medium.com/analytics-vidhya/time-complexity-of-ml-models-4ec39fad2770)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4QY6-p21o1X"
   },
   "source": [
    "6. Calculate the classification metrics for the SVM model. Here you can use a helper function to display all the metrics, inspect the source code to understand how to use the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import display_metrics\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Expected output:</summary>\n",
    "\n",
    "    Confusion Matrix: \n",
    "    [[424424      0]\n",
    "    [     0   6120]]\n",
    "    Accuracy: 1.000\n",
    "    Recall: 1.000\n",
    "    Precision: 1.000\n",
    "    F1 Score: 1.000\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's impressive! Why do you think SVM performs so well? If you are not familiar with Support Vector Machine, check [In-Depth: Support Vector Machines](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.07-Support-Vector-Machines.ipynb) out for better understanding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZoEc46tPKzZ"
   },
   "source": [
    "## Task 5: Fit a non-linear classifier: gradient boosted tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZoEc46tPKzZ"
   },
   "source": [
    "1. Instantiate, train, and predict with the Gradient Boosted Trees model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhRgpHtyGnzD"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhRgpHtyGnzD"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "gbt_model = # YOUR CODE HERE\n",
    "gbt_model.fit(X_train_reduced, y_train)\n",
    "gbt_pred = gbt_model.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLalaVS0rHJ9"
   },
   "source": [
    "2. Evaluate the model by calculating the classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7fQY3dAGnzD"
   },
   "outputs": [],
   "source": [
    "display_metrics(y_test, gbt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Expected output:</summary>\n",
    "\n",
    "    Confusion Matrix: \n",
    "    [[424423      1]\n",
    "    [    16   6104]]\n",
    "    Accuracy: 1.000\n",
    "    Recall: 0.997\n",
    "    Precision: 1.000\n",
    "    F1 Score: 0.999\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VBEOQ9pPKzg"
   },
   "source": [
    "## Task 6: Analyze importace of data sample balancing with random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0qpuZHw5A5I"
   },
   "source": [
    "1. Instantiate, train, predict with, and evaluate an unbalanced random forest classifier. (Follow the same steps you did above with the other models). You can use 100 trees in the forest, and set the maximum depth of the tree at 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQGEtfE1PKzg"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQGEtfE1PKzg"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_model =  # YOUR CODE HERE\n",
    "rf_model.fit(X_train_reduced, y_train)\n",
    "rf_pred = rf_model.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQGEtfE1PKzg"
   },
   "outputs": [],
   "source": [
    "display_metrics(y_test, rf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8r4-4vmtegj"
   },
   "source": [
    "2. Repeat the previous exercise, but this time, incorporate **class-balanced penalty weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5HietxwPKzm"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_model_b = # YOUR CODE HERE\n",
    "rf_model_b.fit(X_train_reduced, y_train)\n",
    "rf_pred_b = rf_model_b.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5HietxwPKzm"
   },
   "outputs": [],
   "source": [
    "display_metrics(y_test, rf_pred_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WM6F1YQ6ADgJ"
   },
   "source": [
    "3. Visualize a Decision Tree. Spend some time inspecting this visualization of the tree--what does each line in the boxes mean? Discuss this with your partners. What does the \"value=...\" line indicate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8zENaJ9PKz1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "\n",
    "export_graphviz(rf_model_b.estimators_[0], max_depth=5, out_file='tree.dot', \n",
    "                feature_names = selected_columns[:-1],\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "# MacOS: brew install graphviz\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9aXqA5MirW7"
   },
   "source": [
    "4. Look at the results below to note the most important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we show you how to use a Random Forest to rank features based on a measure of importance called the Gini Importance. We'll provide you with all the code, but you may want to read up on sklearn's [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and its [feature_importances_](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.feature_importances_) property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eo5IeVYGPKy_"
   },
   "outputs": [],
   "source": [
    "# Use Random Forest to get feature ranks/importances for each feature\n",
    "importances = rf_model_b.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf_model_b.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train_reduced.shape[1]):\n",
    "    print(\"%d. %s (feature %d) (%f)\" %\n",
    "          (f + 1, train_df_reduced.columns[indices[f]], indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train_reduced.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train_reduced.shape[1]), indices)\n",
    "plt.xlim([-1, X_train_reduced.shape[1]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIJA9g5oPKzC"
   },
   "source": [
    "Thus features 4 and 5 (numview, InsessionView) are the top two most important features (according to the Random Forest model). Is this what you expected? Bonus question, is it necessary to scale features for when fitting random forest models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Visualizations with Streamlit and Plotly!\n",
    "Let's write visualize our results in a way that makes it easy to compare our models!  [Streamlit](https://streamlit.io/) is a Python package that makes it easy to create bespoke, dynamic and interactive web apps for visualizations.  Lightweight web apps like this are a great way to present results to stakeholders! \n",
    "\n",
    "First we need to build our results dataset to render in Streamlit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our confusion matricies\n",
    "confusion_lr = confusion_matrix(y_test, lr_pred)\n",
    "confusion_svm = confusion_matrix(y_test, svm_pred)\n",
    "confusion_gb = confusion_matrix(y_test, gbt_pred)\n",
    "confusion_rf = confusion_matrix(y_test, rf_pred_b)\n",
    "\n",
    "# Let's collect all of our metrics!\n",
    "tn = [confusion_lr[0][0], confusion_svm[0][0], confusion_gb[0][0], confusion_rf[0][0]]\n",
    "fp = [confusion_lr[0][1], confusion_svm[0][1], confusion_gb[0][1], confusion_rf[0][1]]\n",
    "fn = [confusion_lr[1][0], confusion_svm[1][0], confusion_gb[1][0], confusion_rf[1][0]]\n",
    "tp = [confusion_lr[1][1], confusion_svm[1][1], confusion_gb[1][1], confusion_rf[1][1]]\n",
    "\n",
    "accuracy_scores = [accuracy(y_test, lr_pred), accuracy(y_test, svm_pred), accuracy(y_test, gbt_pred), accuracy(y_test, rf_pred_b)]\n",
    "recall_scores = [recall(y_test, lr_pred), recall(y_test, svm_pred), recall(y_test, gbt_pred), recall(y_test, rf_pred_b)]\n",
    "f1_scores = [f1_score(y_test, lr_pred), f1_score(y_test, svm_pred), f1_score(y_test, gbt_pred), f1_score(y_test, rf_pred_b)]\n",
    "\n",
    "models = [\"Logistic Regression\", \"SVM\", \"Gradient Boosting Classifier\", \"Random Forest\"]\n",
    "results_data = {\"model\":models, \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp, \"accuracy\": accuracy_scores, \"recall\": recall_scores, \"f1_score\": f1_scores}\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our results_df to CSV\n",
    "results_df.to_csv(\"../dat/model_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go to your terminal, navigate to the folder containing this assignment and run `streamlit run electronics-purchase-predictions-streamlit.py`.  This will open your browser with the streamlit app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Task: Explanability with SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions. You can use package [SHAP](https://github.com/slundberg/shap). \n",
    "\n",
    "For this optional task, if you are not familar with the concept, read the book chapter [Interpretable Machine Learning - A Guide for Making Black Box Models Explainable](https://christophm.github.io/interpretable-ml-book/shap.html) first. Can you apply `shap.Explainer()` to calculate the SHAP values for the XGBoost and Random Forest models you fit earlier, visualize the effects over all samples using `shap.plots.beeswarm()` and interpret the results? Consider experimenting it on a smaller dataset first.  \n",
    "\n",
    "Once you're done, write your data to file and add them under the Model Explainability tab in the Streamlit app, following the example in Model Results tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to get more details? Please go ahead and check these links:\n",
    "\n",
    "1. [Interactive Shapley Value Demonstration in Python](https://github.com/GeostatsGuy/PythonNumericalDemos/blob/master/Interactive_Shapley_Values.ipynb)\n",
    "2. [Subsurface Data Analytics](https://github.com/GeostatsGuy/PythonNumericalDemos/blob/master/SubsurfaceDataAnalytics_Feature_Ranking.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This work is motivated by this [publication](https://arxiv.org/pdf/2010.02503.pdf) \n",
    "- [Comprehensive Guide on Feature Selection](https://www.kaggle.com/code/prashant111/comprehensive-guide-on-feature-selection/notebook)\n",
    "- [Common pitfalls and recommended practices](https://scikit-learn.org/stable/common_pitfalls.html)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "week2_V1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
