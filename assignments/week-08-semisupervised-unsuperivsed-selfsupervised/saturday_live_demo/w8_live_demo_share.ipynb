{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c25a75c9f3ea42bff4e090cb90bf3cde2341a98"
   },
   "source": [
    "# Clustering Algortihms and dimensionality reduction  \n",
    "\n",
    "sources:\n",
    "\n",
    "[Clustering](https://www.kaggle.com/code/fazilbtopal/popular-unsupervised-clustering-algorithms/notebook)\n",
    "\n",
    "[Dim Reduction](https://www.kaggle.com/code/patrickparsa/dimensionality-reduction-pca-and-tsne/notebook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "46264f2aa942327fb740aa3fa54f5c3746f65f4d"
   },
   "source": [
    "## K-Means \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib import style\n",
    "style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Mall_Customers.csv')\n",
    "df.rename(index=str, columns={'Annual Income (k$)': 'Income',\n",
    "                              'Spending Score (1-100)': 'Score'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60429c30e21e07345322bb9990a372b52b313a47"
   },
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(['CustomerID', 'Gender'], axis=1)\n",
    "sns.pairplot(df.drop('CustomerID', axis=1), hue='Gender', aspect=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3e5302415ae26e1e564ed65fc4ed464b85aa2fea"
   },
   "outputs": [],
   "source": [
    "# plotting the inertia for visualizing the elbow plot\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clusters = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    km =   # your code here: defining Kmean clustering the number of clusters is i\n",
    "    clusters.append(km.inertia_)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.lineplot(x=list(range(1, 11)), y=clusters, ax=ax)\n",
    "ax.set_title('Searching for Elbow')\n",
    "ax.set_xlabel('Clusters')\n",
    "ax.set_ylabel('Inertia')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "727664a2b0f592b6e4e4fed1114650c93949d9ba"
   },
   "source": [
    "Elbow method tells us to select the cluster when there is a significant change in inertia. As we can see from the graph, we can say this may be either 3 or 5. Let's see both results in graph and decide.\n",
    "\n",
    "###  Creating the Visual Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b466a3ad8e491085577593d872e6c1085eecbf26"
   },
   "outputs": [],
   "source": [
    "# 3 cluster\n",
    "km3 = #your code here \n",
    "\n",
    "X['Labels'] = km3.labels_\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(X['Income'], X['Score'], hue=X['Labels'], \n",
    "                palette=sns.color_palette('hls', 3))\n",
    "plt.title('KMeans with 3 Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4ab6885ee7c04cceba940b5e46c09d77992e2ce7"
   },
   "outputs": [],
   "source": [
    "# Let's see with 5 Clusters\n",
    "km5 = #your code here \n",
    "\n",
    "X['Labels'] = km5.labels_\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(X['Income'], X['Score'], hue=X['Labels'], \n",
    "                palette=sns.color_palette('hls', 5))\n",
    "plt.title('KMeans with 5 Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "02abec3aef3222ebd3f337767a01deb536cdbd58"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,8))\n",
    "ax = fig.add_subplot(121)\n",
    " #your code for swarmplot from seaborn\n",
    "ax.set_title('Labels According to Annual Income')\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    " #your code for swarmplot from seaborn\n",
    "ax.set_title('Labels According to Scoring History')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Hierarchical Clustering\n",
    "\n",
    "## Agglomerative\n",
    "\n",
    "The <b> Agglomerative Clustering </b> class will require two inputs:\n",
    "<ul>\n",
    "    <li> <b>n_clusters</b>: The number of clusters to form as well as the number of centroids to generate. </li>\n",
    "    <li> <b>linkage</b>: Which linkage criterion to use. The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion. </li>\n",
    "    <ul> \n",
    "        <li> Value will be: 'complete' </li> \n",
    "        <li> <b>Note</b>: It is recommended that try everything with 'average' as well </li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering \n",
    "\n",
    "agglom = #your code here: defining Agglomerative clustering the number of clusters is 5\n",
    "\n",
    "X['Labels'] = agglom.labels_\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(X['Income'], X['Score'], hue=X['Labels'], \n",
    "                palette=sns.color_palette('hls', 5))\n",
    "plt.title('Agglomerative with 5 Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dendrogram Associated for the Agglomerative Hierarchical Clustering\n",
    "Remember that a <b>distance matrix</b> contains the <b> distance from each point to every other point of a dataset </b>. <br>\n",
    "We can use the function <b> distance_matrix, </b> which requires <b>two inputs</b>. \n",
    "Remember that the distance values are symmetric, with a diagonal of 0's. This is one way of making sure your matrix is correct. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy \n",
    "from scipy.spatial import distance_matrix \n",
    "\n",
    "dist = distance_matrix(X, X)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the <b> linkage </b> class from hierarchy, pass in the parameters:\n",
    "<ul>\n",
    "    <li> The distance matrix </li>\n",
    "    <li> 'complete' for complete linkage </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = # your code here for hierarchical clustering using complete linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Hierarchical clustering is typically visualized as a dendrogram as shown in the following cell. Each merge is represented by a horizontal line. The y-coordinate of the horizontal line is the similarity of the two clusters that were merged, where cities are viewed as singleton clusters. \n",
    "By moving up from the bottom layer to the top node, a dendrogram allows us to reconstruct the history of merges that resulted in the depicted clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 50))\n",
    "dendro = # your code here for visualizing dendrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used __complete__ linkage for our case, let's change it to __average__ linkage to see how the dendogram changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "Z = # your code here for hierarchical clustering using average linkage\n",
    "plt.figure(figsize=(18, 50))\n",
    "dendro = hierarchy.dendrogram(Z, leaf_rotation=0, leaf_font_size =12, orientation = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Based Clustering (DBSCAN)\n",
    "### Modeling\n",
    "It works based on two parameters: Epsilon and Minimum Points  \n",
    "__Epsilon__ determine a specified radius that if includes enough number of points within, we call it dense area  \n",
    "__minimumSamples__ determine the minimum number of data points we want in a neighborhood to define a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN \n",
    "\n",
    "db = #your code here for DBSCAN with eps=11 and min_samples=6\n",
    "\n",
    "X['Labels'] = db.labels_\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(X['Income'], X['Score'], hue=X['Labels'], \n",
    "                palette=sns.color_palette('hls', np.unique(db.labels_).shape[0]))\n",
    "plt.title('DBSCAN with epsilon 11, min samples 6')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see DBSCAN doesn't perform very well because the density in our data is not that strong. Label -1 means outliers so it will appear most as outliers. We may have performed better if we had had a bigger data.\n",
    "\n",
    "## OPTICS Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.cluster import OPTICS\n",
    "clustering = #your code here for OPTICS with mins_samples=11 \n",
    "\n",
    "\n",
    "X['Labels'] =clustering.labels_\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(X['Income'], X['Score'], hue=X['Labels'], \n",
    "                palette=sns.color_palette('hls', np.unique(clustering.labels_).shape[0]))\n",
    "plt.plot()\n",
    "plt.title('OPTICS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Up All in One Place\n",
    "\n",
    "Let's visualize all the algorithms we used so far and see their clustering distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "\n",
    "##### KMeans #####\n",
    "ax = fig.add_subplot(221)\n",
    "\n",
    "km5 = KMeans(n_clusters=5).fit(X)\n",
    "X['Labels'] = km5.labels_\n",
    "sns.scatterplot(X['Income'], X['Score'], hue=X['Labels'], style=X['Labels'],\n",
    "                palette=sns.color_palette('hls', 5), s=60, ax=ax)\n",
    "ax.set_title('KMeans with 5 Clusters')\n",
    "\n",
    "\n",
    "##### Agglomerative Clustering #####\n",
    "ax = fig.add_subplot(222)\n",
    "\n",
    "agglom = AgglomerativeClustering(n_clusters=5, linkage='average').fit(X)\n",
    "X['Labels'] = agglom.labels_\n",
    "sns.scatterplot(X['Income'], X['Score'], hue=X['Labels'], style=X['Labels'],\n",
    "                palette=sns.color_palette('hls', 5), s=60, ax=ax)\n",
    "ax.set_title('Agglomerative with 5 Clusters')\n",
    "\n",
    "\n",
    "##### DBSCAN #####\n",
    "ax = fig.add_subplot(223)\n",
    "\n",
    "db = DBSCAN(eps=11, min_samples=6).fit(X)\n",
    "X['Labels'] = db.labels_\n",
    "sns.scatterplot(X['Income'], X['Score'], hue=X['Labels'], style=X['Labels'], s=60,\n",
    "                palette=sns.color_palette('hls', np.unique(db.labels_).shape[0]), ax=ax)\n",
    "ax.set_title('DBSCAN with epsilon 11, min samples 6')\n",
    "\n",
    "\n",
    "##### optics #####\n",
    "ax = fig.add_subplot(224)\n",
    "\n",
    "clustering = OPTICS(min_samples=11).fit(X)\n",
    "X['Labels'] =clustering.labels_\n",
    "sns.scatterplot(X['Income'], X['Score'], hue=X['Labels'], style=X['Labels'], s=60,\n",
    "                palette=sns.color_palette('hls', np.unique(clustering.labels_).shape[0]), ax=ax)\n",
    "ax.set_title('OPTICS')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('auto-mpg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping car_name\n",
    "data1 = data.copy()\n",
    "data = data.drop(['car name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if there are values other than digits in the column 'horsepower' \n",
    "hpIsDigit = pd.DataFrame(data.horsepower.str.isdigit())  # if the string is made of digits store True else False\n",
    "\n",
    "# print isDigit = False!\n",
    "data[hpIsDigit['horsepower'] == False]   # from temp take only those rows where hp has false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "-There are 6 observations where horsepower is ?.\n",
    "\n",
    "-We can consider these values as missing values.\n",
    "\n",
    "-Let's impute these missing values and change the data type of horsepower column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relacing ? with np.nan\n",
    "data = data.replace('?', np.nan)\n",
    "data[hpIsDigit['horsepower'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the missing values with median value\n",
    "data.horsepower.fillna(data.horsepower.median(), inplace=True)\n",
    "data['horsepower'] = data['horsepower'].astype('float64')  # converting the hp column from object data type to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distribution and outliers for each column in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "     print(col)\n",
    "     print('Skew :',round(data[col].skew(),2))\n",
    "     plt.figure(figsize=(15,4))\n",
    "     plt.subplot(1,2,1)\n",
    "     data[col].hist()\n",
    "     plt.ylabel('count')\n",
    "     plt.subplot(1,2,2)\n",
    "     sns.boxplot(x= data[col])\n",
    "     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(data.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data\n",
    "scaler=StandardScaler()\n",
    "data_scaled=pd.DataFrame(scaler.fit_transform(data), columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the number of principal components to generate \n",
    "n=data_scaled.shape[1]\n",
    "\n",
    "#Finding principal components for the data\n",
    "pca =#your code here Applying the PCA algorithm with random state = 1\n",
    "data_pca1 = pd.DataFrame(pca.fit_transform(data_scaled)) #Fitting and transforming the pca function on scaled data\n",
    "\n",
    "#The percentage of variance explained by each principal component\n",
    "exp_var = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the explained variance by individual components\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.plot(range(1,9), exp_var.cumsum(), marker = 'o', linestyle = '--')\n",
    "plt.title(\"Explained Variances by Components\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the least number of components that can explain more than 90% variance\n",
    "sum = 0\n",
    "for ix, i in enumerate(exp_var):\n",
    "  sum = sum + i\n",
    "  if(sum>0.90):\n",
    "    print(\"Number of PCs that explain at least 90% variance: \", ix+1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_comps = ['PC1','PC2','PC3','PC4']\n",
    "data_pca = pd.DataFrame(np.round(pca.components_[:4,:],2),index=pc_comps,columns=data_scaled.columns)\n",
    "data_pca.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([data_pca1, data], axis=1)\n",
    "\n",
    "plt.figure(figsize = (7,7))\n",
    "#Create a scatter plot with x=0 and y=1 using df_concat dataframe\n",
    "sns.scatterplot(x = 0, y = 1, data=df_concat, hue = 'cylinders')\n",
    "\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = #your code here Applying the TSNE algorithm with random state = 1\n",
    "data_tsne = tsne.fit_transform(data_scaled) #Fitting and transforming tsne function on the scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tsne = pd.DataFrame(data = data_tsne, columns = ['Component 1', 'Component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see scatter plot of the data w.r.t number of cylinders\n",
    "sns.scatterplot(x=data_tsne.iloc[:,0],y=data_tsne.iloc[:,1],hue=data.cylinders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assign points to 3 different groups\n",
    "def grouping(x):\n",
    "    first_component = x['Component 1']\n",
    "    second_component = x['Component 2']\n",
    "    if (first_component> 0) and (second_component >0): \n",
    "        return 'group_1'\n",
    "    if (first_component >-20 ) and (second_component >-10):\n",
    "        return 'group_2'\n",
    "    else: \n",
    "        return 'group_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tsne['groups'] = data_tsne.apply(grouping,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=data_tsne.iloc[:,0],y=data_tsne.iloc[:,1],hue=data_tsne.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a732e81fc08c4e379bcf1d3125c34e5a3546a75aa6c8e713d0127d49a44bd91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
